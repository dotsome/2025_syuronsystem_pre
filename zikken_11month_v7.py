# ===============================================
#  å®Ÿé¨“ç”¨ã‚·ã‚¹ãƒ†ãƒ ï¼ˆæ”¹è‰¯ç‰ˆï¼‰
#          â”€â”€ 2æ®µéšMermaidç”Ÿæˆã‚·ã‚¹ãƒ†ãƒ  â”€â”€
# ===============================================
import os, json, subprocess, logging, re, time, csv
from pathlib import Path
from functools import wraps
from logging.handlers import RotatingFileHandler
import streamlit as st
from dotenv import load_dotenv
import openai
import streamlit_authenticator as stauth
import yaml
from yaml.loader import SafeLoader

# =================================================
#                 ãƒšãƒ¼ã‚¸è¨­å®š
# =================================================
# Note: st.set_page_config() must be the first Streamlit command
st.set_page_config(page_title="äººç‰©é–¢ä¿‚æƒ³èµ·ã‚·ã‚¹ãƒ†ãƒ ",
                   page_icon="ğŸ“–", layout="wide")

# -------------------------------------------------
# å…¬é–‹ã‚’é–‹å§‹ã™ã‚‹ãƒšãƒ¼ã‚¸ï¼ˆ0-indexï¼‰
# -------------------------------------------------
START_PAGE = 30 #START_PAGE+1ãƒšãƒ¼ã‚¸ã‹ã‚‰èª­è€…ãŒèª­ã¿é€²ã‚ã¾ã™

# =================================================
#                ğŸ”¸  ãƒ­ã‚¬ãƒ¼é–¢é€£
# =================================================
def _build_logger(log_path: Path) -> logging.Logger:
    """
    ãƒ»ãƒ•ã‚¡ã‚¤ãƒ«      : DEBUG ä»¥ä¸Šã‚’ 1 MB Ã— 5 ä¸–ä»£ã§ä¿å­˜
    ãƒ»ã‚³ãƒ³ã‚½ãƒ¼ãƒ«    : INFO ä»¥ä¸Š
    ãƒ»ContextFilter : user / q_num ã‚’è‡ªå‹•æ³¨å…¥
    """
    class ContextFilter(logging.Filter):
        def filter(self, record: logging.LogRecord) -> bool:
            record.user  = st.session_state.get("user_name", "-")
            record.q_num = st.session_state.get("question_number", 0)
            return True

    fmt_file = "%(asctime)s [%(levelname)s] U:%(user)s Q:%(q_num)s %(funcName)s: %(message)s"
    fmt_term = "%(asctime)s [%(levelname)s] %(message)s"

    logger = logging.getLogger("app")
    logger.setLevel(logging.DEBUG)

    # FileHandler
    h_file = RotatingFileHandler(
        log_path, maxBytes=1_000_000, backupCount=5, encoding="utf-8")
    h_file.setFormatter(logging.Formatter(fmt_file))
    h_file.setLevel(logging.DEBUG)
    h_file.addFilter(ContextFilter())
    logger.addHandler(h_file)

    # Console
    h_term = logging.StreamHandler()
    h_term.setFormatter(logging.Formatter(fmt_term))
    h_term.setLevel(logging.INFO)
    h_term.addFilter(ContextFilter())
    logger.addHandler(h_term)

    logger.propagate = False
    return logger

# -------------------------------------------------
# ãƒ‡ã‚³ãƒ¬ãƒ¼ã‚¿ï¼šå…¥å‡ºåŠ›ï¼†çµŒéæ™‚é–“ã‚’è‡ªå‹•è¨˜éŒ²
# -------------------------------------------------
def log_io(mask: int | None = 400):
    """
    mask=None ãªã‚‰å…¨æ–‡ã€æ•°å€¤ãªã‚‰ãã®æ–‡å­—æ•°ã ã‘ãƒ­ã‚°ã«æ®‹ã™
    """
    def _decorator(func):
        @wraps(func)
        def _wrapper(*args, **kwargs):
            t0 = time.time()
            logger = logging.getLogger("app")
            logger.debug(f"[IN ] {func.__name__} args={args} kwargs={kwargs}")
            try:
                out = func(*args, **kwargs)
                elapsed = time.time() - t0
                if mask is None:
                    out_str = str(out)
                else:
                    out_str = (str(out)[:mask] + "...") if isinstance(out, str) else str(out)
                logger.debug(f"[OUT] {func.__name__} ({elapsed:.2f}s) -> {out_str}")
                return out
            except Exception:
                logger.exception(f"[ERR] {func.__name__}")
                raise
        return _wrapper
    return _decorator

# -------------------------------------------------
# OpenAI å‘¼ã³å‡ºã—ãƒ©ãƒƒãƒ‘
# -------------------------------------------------
@log_io(300)   # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆå†’é ­ 300 æ–‡å­—ã ã‘è¨˜éŒ²
def openai_chat(model: str, messages: list[dict], **kw):
    return client.chat.completions.create(
        model=model,
        messages=messages,
        **kw
    )

# =================================================
#           Streamlit ã‚»ãƒƒã‚·ãƒ§ãƒ³åˆæœŸåŒ–
# =================================================
def init_state(key, default):
    if key not in st.session_state:
        st.session_state[key] = default

init_state("user_name",        "")
init_state("user_number",      "")
init_state("profile_completed", False)  # ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«å…¥åŠ›å®Œäº†ãƒ•ãƒ©ã‚°
init_state("question_number",  0)
init_state("ui_page",          0)   # UI ä¸Šã§ã®ãƒšãƒ¼ã‚¸ï¼ˆ0 â€¦ START_PAGEï¼‰
init_state("messages", [
    {"role": "system",
     "content": "ã‚ãªãŸã¯èª­ã‚“ã§ã„ã‚‹å°èª¬ã«ã¤ã„ã¦è³ªå•ã«ç­”ãˆã‚‹ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚"}
])
init_state("chat_history",     [])

# =================================================
#               èªè¨¼è¨­å®š
# =================================================
yaml_path = "config.yaml"
with open(yaml_path) as file:
    config = yaml.load(file, Loader=SafeLoader)

authenticator = stauth.Authenticate(
    credentials=config['credentials'],
    cookie_name=config['cookie']['name'],
    cookie_key=config['cookie']['key'],
    cookie_expiry_days=config['cookie']['expiry_days'],
)

# =================================================
#               èªè¨¼å‡¦ç†
# =================================================
authenticator.login()

if st.session_state["authentication_status"] is False:
    # ãƒ­ã‚°ã‚¤ãƒ³å¤±æ•—
    st.error('Username/password is incorrect')
    st.stop()

elif st.session_state["authentication_status"] is None:
    # æœªèªè¨¼
    st.warning('Please enter your username and password')
    st.stop()

elif st.session_state["authentication_status"]:
    # ãƒ­ã‚°ã‚¤ãƒ³æˆåŠŸ - ã‚µã‚¤ãƒ‰ãƒãƒ¼ã«ãƒ­ã‚°ã‚¢ã‚¦ãƒˆãƒœã‚¿ãƒ³ã‚’è¿½åŠ 
    with st.sidebar:
        st.markdown(f'## Welcome *{st.session_state["name"]}*')
        authenticator.logout('Logout', 'sidebar')
        st.divider()

    # ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«å…¥åŠ›ãŒå®Œäº†ã—ã¦ã„ãªã„å ´åˆã€ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«å…¥åŠ›ç”»é¢ã‚’è¡¨ç¤º
    if not st.session_state.profile_completed:
        st.title("ğŸ“ ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«å…¥åŠ›")
        st.markdown("### å®Ÿé¨“å‚åŠ æƒ…å ±ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")

        with st.form("profile_form"):
            nickname = st.text_input("ãƒ‹ãƒƒã‚¯ãƒãƒ¼ãƒ ",
                                     placeholder="ä¾‹: Taro",
                                     help="ãƒ•ã‚¡ã‚¤ãƒ«åã«ä½¿ç”¨ã•ã‚Œã¾ã™")
            experiment_number = st.text_input("å®Ÿé¨“ãƒŠãƒ³ãƒãƒ¼",
                                              placeholder="ä¾‹: EXP001",
                                              help="ãƒ•ã‚¡ã‚¤ãƒ«åã«ä½¿ç”¨ã•ã‚Œã¾ã™")
            submitted = st.form_submit_button("æ¬¡ã¸")

            if submitted:
                if nickname and experiment_number:
                    st.session_state.user_name = nickname
                    st.session_state.user_number = experiment_number
                    st.session_state.profile_completed = True
                    st.success("ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«è¨­å®šå®Œäº†!")
                    st.rerun()
                else:
                    st.error("ãƒ‹ãƒƒã‚¯ãƒãƒ¼ãƒ ã¨å®Ÿé¨“ãƒŠãƒ³ãƒãƒ¼ã®ä¸¡æ–¹ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")

        # ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«å…¥åŠ›ç”»é¢ã§ã¯ã“ã“ã§åœæ­¢
        st.stop()

# =================================================
#          ğŸ”¸ ãƒ¦ãƒ¼ã‚¶ãƒ¼åˆ¥ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª & ãƒ­ã‚°
# =================================================
# zikken_result ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ä½œæˆ
base_dir = Path("zikken_result")
base_dir.mkdir(exist_ok=True)

# ãƒ¦ãƒ¼ã‚¶ãƒ¼åˆ¥ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ zikken_result é…ä¸‹ã«ä½œæˆ
user_dir = base_dir / f"zikken_{st.session_state.user_name}_{st.session_state.user_number}"
user_dir.mkdir(exist_ok=True)

log_file = user_dir / f"{st.session_state.user_name}_{st.session_state.user_number}_chat_log.txt"
logger   = _build_logger(log_file)
logger.info("--- Session started ---")

# =================================================
#          OpenAI ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆåˆæœŸåŒ–
# =================================================
load_dotenv()
api_key = os.getenv("OPENAI_API_KEY")
if not api_key:
    st.error("OPENAI_API_KEY ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
    st.stop()

client = openai.OpenAI(api_key=api_key)

st.title(f"ğŸ“– å®Ÿé¨“ç”¨ã‚·ã‚¹ãƒ†ãƒ  - "
         f"{st.session_state.user_name} / {st.session_state.user_number}")

# =================================================
#              å°èª¬ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
# =================================================
@st.cache_data
@log_io()                 # èª­ã¿è¾¼ã¿çŠ¶æ³ã‚‚è¨˜éŒ²
def load_story(filename="beast_text.json"):
    try:
        with open(filename, "r", encoding="utf-8") as f:
            return json.load(f)
    except FileNotFoundError:
        st.warning("âš ï¸ beast_text.json ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚ãƒ€ãƒŸãƒ¼ãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚")
        return [
            {"section": "1", "title": "åºç« ",
             "text": "ã“ã‚Œã¯ç‰©èªã®å§‹ã¾ã‚Šã§ã™ã€‚ä¸»äººå…¬ã®å¤ªéƒã¯ã€ç•°ä¸–ç•Œã«è»¢ç”Ÿã—ã¾ã—ãŸã€‚"},
            {"section": "2", "title": "å‡ºä¼šã„",
             "text": "å¤ªéƒã¯æ£®ã§ä¸æ€è­°ãªç£ã¨å‡ºä¼šã„ã¾ã—ãŸã€‚ãã®ç£ã®åå‰ã¯ã‚·ãƒ­ã¨è¨€ã„ã¾ã—ãŸã€‚"}
        ]

story_sections = load_story()
pages_all = [f"ã€{sec['section']}ç« ã€‘ {sec['title']}\n\n{sec['text']}"
             for sec in story_sections]
pages_ui       = pages_all[START_PAGE:]
total_ui_pages = len(pages_ui)
total_pages    = len(pages_all)

# =================================================
# GPT 4oï¼šç™»å ´äººç‰©è³ªå•ã®åˆ¤å®š
# =================================================
@log_io()
def is_character_question(question: str) -> bool:
    prompt = f"ä»¥ä¸‹ã®è³ªå•ãŒã€ç™»å ´äººç‰©ã€ã«é–¢ã™ã‚‹ã‚‚ã®ã‹ Yes / No ã§ç­”ãˆã¦ãã ã•ã„ã€‚\n\nè³ªå•: {question}"
    try:
        res = openai_chat(
            "gpt-4o",
            messages=[
                {"role": "system", "content": "è³ªå•ãŒç™»å ´äººç‰©ã«é–¢ã™ã‚‹ã‹åˆ¤å®šã—ã¾ã™ã€‚"},
                {"role": "user",   "content": prompt}
            ],
            temperature=0
        )
        answer = res.choices[0].message.content.strip().lower()
        return "yes" in answer
    except Exception as e:
        logger.exception("is_character_question Error")
        return False

# =================================================
# æ”¹è‰¯ç‰ˆ Mermaid å›³ç”Ÿæˆï¼ˆ2æ®µéšãƒ—ãƒ­ã‚»ã‚¹ï¼‰
# =================================================
@log_io(mask=None)
def generate_mermaid_file(question: str, story_text: str, q_num: int) -> str | None:
    """
    2æ®µéšãƒ—ãƒ­ã‚»ã‚¹ï¼š
    1. GPTã§ã–ã£ãã‚ŠMermaidå›³ã‚’ç”Ÿæˆ
    2. ãã‚Œã‚’CSVã«å¤‰æ›ã—ã¦æ¤œè¨¼
    3. ãƒ«ãƒ¼ãƒ«ãƒ™ãƒ¼ã‚¹ã§æœ€çµ‚çš„ãªMermaidå›³ã‚’æ§‹ç¯‰
    """
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # Step 1: è³ªå•ã®ä¸­å¿ƒäººç‰©ã‚’ç‰¹å®š
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    who_prompt = f"""
è³ªå•ã€Œ{question}ã€ã®ä¸­å¿ƒã¨ãªã‚‹ç™»å ´äººç‰©ã®åå‰ã‚’1ã¤ã ã‘ç­”ãˆã¦ãã ã•ã„ã€‚
æœ¬æ–‡ã«ç™»å ´ã™ã‚‹äººç‰©åã§ç­”ãˆã‚‹ã“ã¨ã€‚

æœ¬æ–‡ï¼ˆå†’é ­ï¼‰:
{story_text[:1000]}
"""
    
    try:
        res_who = openai_chat(
            "gpt-4o",
            messages=[
                {"role": "system", "content": "è³ªå•ã®ä¸­å¿ƒäººç‰©ã‚’ç‰¹å®šã—ã¾ã™ã€‚"},
                {"role": "user", "content": who_prompt}
            ],
            temperature=0
        )
        main_focus = res_who.choices[0].message.content.strip().splitlines()[0]
    except Exception:
        logger.exception("[Mermaid] main focus extraction error")
        main_focus = "ä¸»äººå…¬"
    
    logger.info(f"[Q{q_num}] Main focus = {main_focus}")

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # Step 2: ä¸­å¿ƒäººç‰©ã‚’åŸºã«ã–ã£ãã‚ŠMermaidå›³ã‚’ç”Ÿæˆ
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    rough_mermaid_prompt = f"""
ä»¥ä¸‹ã®è³ªå•ã¨æœ¬æ–‡ã‚’åŸºã«ã€ã€Œ{main_focus}ã€ã‚’ä¸­å¿ƒã¨ã—ãŸç™»å ´äººç‰©ã®é–¢ä¿‚ã‚’è¡¨ã™Mermaidå›³ã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚

è³ªå•: {question}

æœ¬æ–‡:
{story_text}

è¦ä»¶:
- graph LR ã¾ãŸã¯ graph TD ã§é–‹å§‹
- {main_focus}ã‚’ä¸­å¿ƒã«é…ç½®ã—ã€é–¢é€£ã™ã‚‹äººç‰©ã¨ã®é–¢ä¿‚ã‚’æ˜ç¢ºã«è¡¨ç¾
- ç™»å ´äººç‰©ã‚’ãƒãƒ¼ãƒ‰ã¨ã—ã¦è¡¨ç¾
- é–¢ä¿‚æ€§ã‚’çŸ¢å°ã§è¡¨ç¾
- å¿…è¦ã«å¿œã˜ã¦subgraphã§ã‚°ãƒ«ãƒ¼ãƒ—åŒ–
- åŒæ–¹å‘ã®é–¢ä¿‚ã¯ <--> ã§è¡¨ç¾
- ä¸€æ–¹å‘ã®é–¢ä¿‚ã¯ --> ã§è¡¨ç¾
- ç‚¹ç·šçŸ¢å° -.-> ã‚‚ä½¿ç”¨å¯
- ã‚¨ãƒƒã‚¸ã«ã¯æ—¥æœ¬èªã§ãƒ©ãƒ™ãƒ«ã‚’ä»˜ã‘ã‚‹
- {main_focus}ã«ç›´æ¥ã¾ãŸã¯é–“æ¥çš„ã«é–¢ã‚ã‚‹äººç‰©ã‚’å„ªå…ˆçš„ã«å«ã‚ã‚‹

å‡ºåŠ›ã¯Mermaidã‚³ãƒ¼ãƒ‰ã®ã¿ï¼ˆèª¬æ˜ä¸è¦ï¼‰
"""
    
    try:
        res_rough = openai_chat(
            "gpt-4.1",  # é«˜é€ŸåŒ–ã®ãŸã‚
            messages=[
                {"role": "system", "content": "Mermaidå›³ã‚’ç”Ÿæˆã™ã‚‹å°‚é–€å®¶ã§ã™ã€‚"},
                {"role": "user", "content": rough_mermaid_prompt}
            ],
            temperature=0.3
        )
        rough_mermaid = res_rough.choices[0].message.content.strip()
        # ã‚³ãƒ¼ãƒ‰ãƒ–ãƒ­ãƒƒã‚¯è¨˜å·ã‚’é™¤å»
        rough_mermaid = rough_mermaid.replace('```mermaid', '').replace('```', '').strip()
        logger.debug(f"[Q{q_num}] Rough Mermaid = {rough_mermaid[:500]}")
    except Exception:
        logger.exception("[Mermaid] Rough generation error")
        rough_mermaid = f"graph LR\n    {main_focus} --> èª°ã‹"

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # Step 3: Mermaidå›³ã‚’CSVã«å¤‰æ›ï¼ˆæ¤œè¨¼ã®ãŸã‚ï¼‰
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    csv_prompt = f"""
ä»¥ä¸‹ã®Mermaidå›³ã‹ã‚‰äººç‰©é–¢ä¿‚ã‚’æŠ½å‡ºã—ã¦CSVå½¢å¼ã§å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚
ç‰¹ã«ã€Œ{main_focus}ã€ã«é–¢é€£ã™ã‚‹é–¢ä¿‚ã‚’å„ªå…ˆçš„ã«æŠ½å‡ºã—ã¦ãã ã•ã„ã€‚

Mermaidå›³:
{rough_mermaid}

æœ¬æ–‡ï¼ˆå‚è€ƒï¼‰:
{story_text[:2000]}  # é•·ã™ãã‚‹å ´åˆã¯å†’é ­ã®ã¿

å‡ºåŠ›å½¢å¼:
ä¸»ä½“,é–¢ä¿‚ã‚¿ã‚¤ãƒ—,é–¢ä¿‚è©³ç´°,å®¢ä½“,ã‚°ãƒ«ãƒ¼ãƒ—

èª¬æ˜:
- ä¸»ä½“: é–¢ä¿‚ã®èµ·ç‚¹ã¨ãªã‚‹äººç‰©
- é–¢ä¿‚ã‚¿ã‚¤ãƒ—: directedï¼ˆä¸€æ–¹å‘ï¼‰, bidirectionalï¼ˆåŒæ–¹å‘ï¼‰, dottedï¼ˆç‚¹ç·šï¼‰
- é–¢ä¿‚è©³ç´°: é–¢ä¿‚ã‚’è¡¨ã™æ—¥æœ¬èªï¼ˆ10æ–‡å­—ä»¥å†…ï¼‰
- å®¢ä½“: é–¢ä¿‚ã®çµ‚ç‚¹ã¨ãªã‚‹äººç‰©  
- ã‚°ãƒ«ãƒ¼ãƒ—: subgraphã«å±ã™ã‚‹å ´åˆã¯ã‚°ãƒ«ãƒ¼ãƒ—åã€ãªã‘ã‚Œã°ç©ºæ¬„

æ³¨æ„:
- ãƒ˜ãƒƒãƒ€ãƒ¼ã¯ä¸è¦
- æœ¬æ–‡ã«å­˜åœ¨ã—ãªã„äººç‰©é–¢ä¿‚ã¯é™¤å¤–
- {main_focus}ã«é–¢é€£ã™ã‚‹é‡è¦åº¦ã®é«˜ã„é †ã«ä¸¦ã¹ã‚‹
"""

    try:
        res_csv = openai_chat(
            "gpt-4.1",
            messages=[
                {"role": "system", "content": "Mermaidå›³ã¨æœ¬æ–‡ã‚’ç…§åˆã—ã¦æ­£ç¢ºãªé–¢ä¿‚ã‚’æŠ½å‡ºã—ã¾ã™ã€‚"},
                {"role": "user", "content": csv_prompt}
            ],
            temperature=0
        )
        csv_text = res_csv.choices[0].message.content.strip()
        logger.debug(f"[Q{q_num}] Validated CSV = {csv_text[:400]}")
    except Exception:
        logger.exception("[Mermaid] CSV conversion error")
        csv_text = f"{main_focus},directed,é–¢ä¿‚,èª°ã‹,"

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # Step 4: CSVã‹ã‚‰ãƒ«ãƒ¼ãƒ«ãƒ™ãƒ¼ã‚¹ã§Mermaidå›³ã‚’å†æ§‹ç¯‰
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    def build_mermaid_from_csv(csv_text: str, main_focus: str = None) -> str:
        """
        CSVãƒ‡ãƒ¼ã‚¿ã‹ã‚‰æ­£ç¢ºãªMermaidå›³ã‚’æ§‹ç¯‰
        """
        # ãƒãƒ¼ãƒ‰ã¨ã‚¨ãƒƒã‚¸ã®åé›†
        nodes = set()
        edges = []
        groups = {}  # ã‚°ãƒ«ãƒ¼ãƒ—å -> ãƒãƒ¼ãƒ‰ãƒªã‚¹ãƒˆ
        
        reader = csv.reader(csv_text.splitlines())
        for row in reader:
            if len(row) < 4:
                continue
            
            src = row[0].strip()
            rel_type = row[1].strip() if len(row) > 1 else "directed"
            rel_label = row[2].strip() if len(row) > 2 else "é–¢ä¿‚"
            dst = row[3].strip() if len(row) > 3 else ""
            group = row[4].strip() if len(row) > 4 else ""
            
            if not src or not dst:
                continue
            
            nodes.add(src)
            nodes.add(dst)
            
            # ã‚°ãƒ«ãƒ¼ãƒ—ã®è¨˜éŒ²
            if group:
                if group not in groups:
                    groups[group] = set()
                groups[group].add(src)
                groups[group].add(dst)
            
            # ã‚¨ãƒƒã‚¸ã®è¨˜éŒ²
            edge_symbol = "-->"  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ
            if rel_type.lower() in ["bidirectional", "åŒæ–¹å‘"]:
                edge_symbol = "<-->"
            elif rel_type.lower() in ["dotted", "ç‚¹ç·š"]:
                edge_symbol = "-.->"
            
            edges.append({
                "src": src,
                "dst": dst,
                "symbol": edge_symbol,
                "label": rel_label[:10]  # 10æ–‡å­—åˆ¶é™
            })
        
        # Mermaidå›³ã®æ§‹ç¯‰
        lines = ["graph LR"]
        
        # ãƒãƒ¼ãƒ‰IDã®ç”Ÿæˆï¼ˆå®‰å…¨ãªè­˜åˆ¥å­ï¼‰
        def safe_id(name: str) -> str:
            # æ—¥æœ¬èªã‚’ãã®ã¾ã¾ä½¿ãˆã‚‹å ´åˆ
            return f'id_{abs(hash(name)) % 10000}'
        
        node_ids = {name: safe_id(name) for name in nodes}
        
        # ãƒãƒ¼ãƒ‰å®šç¾©
        for name in sorted(nodes):
            node_id = node_ids[name]
            lines.append(f'    {node_id}["{name}"]')
        
        # ã‚µãƒ–ã‚°ãƒ©ãƒ•ã®å®šç¾©
        if groups:
            for group_name, group_nodes in groups.items():
                safe_group_name = re.sub(r'[^0-9A-Za-z_\u3040-\u30FF\u4E00-\u9FFF\s]', '', group_name)
                lines.append(f'\n    subgraph {safe_group_name}')
                for node in group_nodes:
                    if node in node_ids:
                        lines.append(f'        {node_ids[node]}')
                lines.append('    end')
        
        # ã‚¨ãƒƒã‚¸ã®å®šç¾©
        lines.append('')  # ç©ºè¡Œ
        for edge in edges:
            if edge["src"] in node_ids and edge["dst"] in node_ids:
                src_id = node_ids[edge["src"]]
                dst_id = node_ids[edge["dst"]]
                
                if edge["label"]:
                    if edge["symbol"] == "<-->":
                        lines.append(f'    {src_id} <-->|{edge["label"]}| {dst_id}')
                    elif edge["symbol"] == "-.->":
                        lines.append(f'    {src_id} -.->|{edge["label"]}| {dst_id}')
                    else:
                        lines.append(f'    {src_id} -->|{edge["label"]}| {dst_id}')
                else:
                    lines.append(f'    {src_id} {edge["symbol"]} {dst_id}')
        
        # ä¸­å¿ƒäººç‰©ã®å¼·èª¿
        if main_focus and main_focus in node_ids:
            lines.append(f'\n    style {node_ids[main_focus]} fill:#FFD700,stroke:#FF8C00,stroke-width:4px')
        
        return '\n'.join(lines)

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # Step 5: æœ€çµ‚çš„ãªMermaidå›³ã‚’ç”Ÿæˆ
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    final_mermaid = build_mermaid_from_csv(csv_text, main_focus)
    logger.debug(f"[Q{q_num}] Final Mermaid = {final_mermaid[:500]}")

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # Step 6: Mermaid CLIã§PNGç”Ÿæˆ
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    mmd_path = Path(user_dir) / f"{st.session_state.user_name}_{st.session_state.user_number}_{q_num}.mmd"
    png_path = mmd_path.with_suffix(".png")
    
    # Mermaidãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¿å­˜
    mmd_path.write_text(final_mermaid, encoding="utf-8")
    
    # ãƒ‡ãƒãƒƒã‚°ç”¨ï¼šç”Ÿæˆã•ã‚ŒãŸMermaidã‚³ãƒ¼ãƒ‰ã‚‚ä¿å­˜
    debug_path = Path(user_dir) / f"debug_mermaid_{q_num}.txt"
    debug_content = f"""=== ROUGH MERMAID ===
{rough_mermaid}

=== CSV DATA ===
{csv_text}

=== FINAL MERMAID ===
{final_mermaid}
"""
    debug_path.write_text(debug_content, encoding="utf-8")

    try:
        # Mermaid CLIã§PNGç”Ÿæˆ
        result = subprocess.run(
            ["mmdc", "-i", str(mmd_path), "-o", str(png_path),
             "-t", "default", "-b", "white"],
            capture_output=True,
            text=True,
            timeout=30,
            check=True
        )
        logger.info(f"[Q{q_num}] PNG generated successfully")
        return str(png_path)
        
    except FileNotFoundError:
        st.error("âŒ mmdc ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚`npm install -g @mermaid-js/mermaid-cli` ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚")
        st.code(final_mermaid, language="mermaid")
        return None
    except subprocess.CalledProcessError as e:
        st.warning("âš ï¸ Mermaid å›³ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸã€‚ç”Ÿæˆã•ã‚ŒãŸã‚³ãƒ¼ãƒ‰ã‚’è¡¨ç¤ºã—ã¾ã™ã€‚")
        st.code(final_mermaid, language="mermaid")
        st.error(f"ã‚¨ãƒ©ãƒ¼è©³ç´°: {e.stderr}")
        logger.exception(f"Mermaid generation failed: {e.stderr}")
        return None
    except subprocess.TimeoutExpired:
        st.warning("âš ï¸ Mermaid å›³ç”ŸæˆãŒã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã—ã¾ã—ãŸã€‚")
        st.code(final_mermaid, language="mermaid")
        logger.warning("Mermaid generation timeout")
        return None

# =================================================
#                   ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆ
# =================================================
left_col, right_col = st.columns([5, 4])

# -------------------------------------------------
# å·¦ï¼šå°èª¬è¡¨ç¤ºã¨è³ªå•å…¥åŠ›
# -------------------------------------------------
with left_col:
    st.markdown("### ğŸ“– å°èª¬")
    real_page_index = START_PAGE + st.session_state.ui_page

    nav1, nav2, nav3 = st.columns([1, 3, 1])
    with nav1:
        if st.button("â—€ å‰ã¸", disabled=(st.session_state.ui_page == 0)):
            logger.info(f"Navigate prev -> UI page {st.session_state.ui_page-1}")
            st.session_state.ui_page -= 1
            st.rerun()
    with nav2:
        st.markdown(f"<center>ãƒšãƒ¼ã‚¸ {real_page_index + 1} / {total_pages}</center>",
                    unsafe_allow_html=True)
    with nav3:
        if st.button("æ¬¡ã¸ â–¶",
                     disabled=(st.session_state.ui_page >= total_ui_pages-1)):
            logger.info(f"Navigate next -> UI page {st.session_state.ui_page+1}")
            st.session_state.ui_page += 1
            st.rerun()

    st.session_state.page = real_page_index
    st.markdown(
        f"""
        <div style="
            padding:20px;border-radius:10px;background-color:#FFF8DC;
            font-size:18px;line-height:1.8;white-space:pre-wrap;
            min-height:500px;max-height:600px;overflow-y:auto;">
        {pages_all[real_page_index]}
        </div>
        """, unsafe_allow_html=True
    )

    st.markdown("### ğŸ’¬ è³ªå•")
    user_input = st.chat_input("ã“ã®å°èª¬ã«ã¤ã„ã¦è³ªå•ã§ãã¾ã™", key="main_input")

    st.markdown("---")
    info1, info2, info3 = st.columns(3)
    info1.metric("ãƒ¦ãƒ¼ã‚¶ãƒ¼",   st.session_state.user_name)
    info2.metric("ãƒŠãƒ³ãƒãƒ¼",   st.session_state.user_number)
    info3.metric("è³ªå•æ•°",     st.session_state.question_number)

# -------------------------------------------------
# å³ï¼šå±¥æ­´ & å›³ & ãƒ­ã‚° DL
# -------------------------------------------------
with right_col:
    st.markdown("### ğŸ“ è³ªå•ãƒ»å›ç­”å±¥æ­´")
    chat_box = st.container(height=650)

    with chat_box:
        if not st.session_state.chat_history:
            st.info("ã¾ã è³ªå•ãŒã‚ã‚Šã¾ã›ã‚“ã€‚å·¦å´ã®å…¥åŠ›æ¬„ã‹ã‚‰è³ªå•ã—ã¦ãã ã•ã„ã€‚")
        else:
            for item in st.session_state.chat_history:
                if item["type"] == "question":
                    st.markdown(
                        f'<div style="background:#DCF8C6;padding:10px;border-radius:10px;margin:5px 0;">'
                        f'<b>Q{item["number"]}:</b> {item["content"]}</div>',
                        unsafe_allow_html=True)
                elif item["type"] == "answer":
                    st.markdown(
                        f'<div style="background:#F1F0F0;padding:10px;border-radius:10px;margin:5px 0;">'
                        f'<b>A:</b> {item["content"]}</div>',
                        unsafe_allow_html=True)
                elif item["type"] == "image" and Path(item["path"]).exists():
                    st.image(item["path"], caption=item["caption"],
                             width='stretch')

    st.markdown("### ğŸ“¥ ãƒ­ã‚°")
    with open(log_file, "r", encoding="utf-8") as f:
        st.download_button("ãƒ­ã‚°ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰", f.read(),
                           file_name=log_file.name, mime="text/plain")

# =================================================
#               ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›å‡¦ç†
# =================================================
if user_input:
    st.session_state.question_number += 1
    q_num = st.session_state.question_number
    logger.info(f"[Q{q_num}] {user_input}")

    st.session_state.chat_history.append(
        {"type": "question", "number": q_num, "content": user_input}
    )

    thinking_msg = f"ã€{user_input}ã€ã«ã¤ã„ã¦æ€è€ƒä¸­ã§ã™â€¦"
    idx_thinking = len(st.session_state.chat_history)
    st.session_state.chat_history.append(
        {"type": "answer", "content": thinking_msg, "tmp": True}
    )

    story_text_so_far = "\n\n".join(pages_all[:real_page_index + 1])

    png_file = None
    if is_character_question(user_input):
        with st.spinner("ç™»å ´äººç‰©ã®é–¢ä¿‚å›³ã‚’ç”Ÿæˆä¸­..."):
            png_file = generate_mermaid_file(user_input, story_text_so_far, q_num)
            if png_file:
                st.session_state.chat_history.append(
                    {"type": "image",
                     "path": png_file,
                     "caption": f"ç™»å ´äººç‰©é–¢ä¿‚å›³ (è³ªå• #{q_num})"})

    prompt = f"""
ä»¥ä¸‹ã¯ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒã“ã‚Œã¾ã§ã«èª­ã‚“ã å°èª¬æœ¬æ–‡ã§ã™ã€‚

----- æœ¬æ–‡ã“ã“ã‹ã‚‰ -----
{story_text_so_far}
----- æœ¬æ–‡ã“ã“ã¾ã§ -----

# æŒ‡ç¤º
ã“ã®æœ¬æ–‡ã®å†…å®¹ã‚’æ ¹æ‹ ã«ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã«æ—¥æœ¬èªã§ä¸å¯§ã«ç­”ãˆã¦ãã ã•ã„ã€‚
"""
    st.session_state.messages.append(
        {"role": "user", "content": prompt + "\n\nè³ªå•: " + user_input}
    )

    try:
        with st.spinner("å›ç­”ã‚’ç”Ÿæˆä¸­..."):
            resp  = openai_chat(
                        "gpt-4.1",
                        messages=st.session_state.messages,
                        temperature=0.7
                    )
            reply = resp.choices[0].message.content.strip()

        st.session_state.chat_history[idx_thinking] = {
            "type": "answer", "content": reply
        }
        st.session_state.messages.append(
            {"role": "assistant", "content": reply})
        logger.info(f"[A{q_num}] å›ç­”ç”Ÿæˆå®Œäº†")

    except Exception as e:
        err = f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}"
        st.session_state.chat_history[idx_thinking] = {
            "type": "answer", "content": err
        }
        st.error(err)
        logger.exception("å›ç­”ç”Ÿæˆå¤±æ•—")

    st.rerun()
