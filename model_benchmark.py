"""
Mermaidå›³ç”Ÿæˆã®ãƒ¢ãƒ‡ãƒ«åˆ¥ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æ¤œè¨¼ã‚¹ã‚¯ãƒªãƒ—ãƒˆ

ä½¿ç”¨æ–¹æ³•:
    python model_benchmark.py

å‡ºåŠ›:
    - benchmark_results.csv: å„ãƒ¢ãƒ‡ãƒ«ã®å‡¦ç†æ™‚é–“ã¨ãƒˆãƒ¼ã‚¯ãƒ³ä½¿ç”¨é‡
    - benchmark_details.txt: è©³ç´°ãªãƒ­ã‚°
"""

import os
import json
import time
import csv
from pathlib import Path
from datetime import datetime
from dotenv import load_dotenv
import openai

# ç’°å¢ƒå¤‰æ•°èª­ã¿è¾¼ã¿
load_dotenv()
api_key = os.getenv("OPENAI_API_KEY")
if not api_key:
    print("âŒ OPENAI_API_KEY ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
    exit(1)

client = openai.OpenAI(api_key=api_key)

# ===============================================
#  ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿
# ===============================================
def load_test_data(filename="beast_text.json"):
    """å°èª¬ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã‚€"""
    try:
        with open(filename, "r", encoding="utf-8") as f:
            story_sections = json.load(f)

        # å…¨ç« ã®ãƒ†ã‚­ã‚¹ãƒˆã‚’çµåˆ
        story_text = "\n\n".join([
            f"ã€{sec['section']}ç« ã€‘ {sec['title']}\n\n{sec['text']}"
            for sec in story_sections
        ])

        return story_text
    except FileNotFoundError:
        print(f"âŒ {filename} ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        exit(1)

# ===============================================
#  Mermaidå›³ç”Ÿæˆé–¢æ•°
# ===============================================
def generate_mermaid_rough(model: str, question: str, story_text: str, main_focus: str = "ã‚¿ãƒ‹ã‚¢") -> dict:
    """
    æŒ‡å®šã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã§Mermaidå›³ã‚’ç”Ÿæˆã—ã€å‡¦ç†æ™‚é–“ã¨ãƒˆãƒ¼ã‚¯ãƒ³æ•°ã‚’è¨ˆæ¸¬

    Returns:
        dict: {
            'model': ãƒ¢ãƒ‡ãƒ«å,
            'time': å‡¦ç†æ™‚é–“(ç§’),
            'prompt_tokens': ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒˆãƒ¼ã‚¯ãƒ³æ•°,
            'completion_tokens': å®Œäº†ãƒˆãƒ¼ã‚¯ãƒ³æ•°,
            'total_tokens': åˆè¨ˆãƒˆãƒ¼ã‚¯ãƒ³æ•°,
            'mermaid_code': ç”Ÿæˆã•ã‚ŒãŸMermaidã‚³ãƒ¼ãƒ‰,
            'error': ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ (ã‚¨ãƒ©ãƒ¼æ™‚ã®ã¿)
        }
    """
    prompt = f"""
ä»¥ä¸‹ã®è³ªå•ã¨æœ¬æ–‡ã‚’åŸºã«ã€ã€Œ{main_focus}ã€ã‚’ä¸­å¿ƒã¨ã—ãŸä¸»è¦ç™»å ´äººç‰©ã®é–¢ä¿‚å›³ã‚’Mermaidå½¢å¼ã§ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚

è³ªå•: {question}

æœ¬æ–‡:
{story_text}

è¦ä»¶:
- graph LR ã¾ãŸã¯ graph TD ã§é–‹å§‹
- **{main_focus}ã‚’ä¸­å¿ƒ**ã«ã€ç›´æ¥é–¢ã‚ã‚‹ä¸»è¦äººç‰©ã®ã¿ã‚’å«ã‚ã‚‹
- ç™»å ´äººç‰©ã¯ç‰©èªä¸Šé‡è¦ãªäººç‰©ã«é™å®šã™ã‚‹ï¼ˆ5-10äººç¨‹åº¦ï¼‰
- é–¢ä¿‚æ€§ã®è¡¨ç¾ï¼š
  * åŒæ–¹å‘ã®é–¢ä¿‚: <--> ã‚’ä½¿ç”¨ï¼ˆä¾‹: å‹äººã€ä»²é–“ã€æ‹äººãªã©ï¼‰
  * ä¸€æ–¹å‘ã®é–¢ä¿‚: --> ã‚’ä½¿ç”¨ï¼ˆä¾‹: ä¸Šå¸â†’éƒ¨ä¸‹ã€å¸«åŒ â†’å¼Ÿå­ãªã©ï¼‰
  * ç‚¹ç·šçŸ¢å° -.-> ã¯è£œåŠ©çš„ãªé–¢ä¿‚ã«ä½¿ç”¨
- **é‡è¦**: åŒã˜2äººã®é–“ã®é–¢ä¿‚ã¯æœ€å¤§2æœ¬ã¾ã§ï¼ˆAã‹ã‚‰Bã€Bã‹ã‚‰Aï¼‰
- ã‚¨ãƒƒã‚¸ã«ã¯ç°¡æ½”ãªæ—¥æœ¬èªãƒ©ãƒ™ãƒ«ã‚’ä»˜ã‘ã‚‹ï¼ˆ5æ–‡å­—ä»¥å†…æ¨å¥¨ï¼‰
- å¿…è¦ã«å¿œã˜ã¦subgraphã§ã‚°ãƒ«ãƒ¼ãƒ—åŒ–ï¼ˆä¾‹: å‹‡è€…ãƒ‘ãƒ¼ãƒ†ã‚£ãƒ¼ã€é­”ç‹è»ãªã©ï¼‰
- {main_focus}ã«ç›´æ¥é–¢ã‚ã‚‰ãªã„äººç‰©é–“ã®é–¢ä¿‚ã¯çœç•¥ã™ã‚‹

å‡ºåŠ›ã¯Mermaidã‚³ãƒ¼ãƒ‰ã®ã¿ï¼ˆèª¬æ˜ä¸è¦ï¼‰
"""

    result = {
        'model': model,
        'time': 0,
        'prompt_tokens': 0,
        'completion_tokens': 0,
        'total_tokens': 0,
        'mermaid_code': '',
        'error': None
    }

    try:
        start_time = time.time()

        response = client.chat.completions.create(
            model=model,
            messages=[
                {"role": "system", "content": "Mermaidå›³ã‚’ç”Ÿæˆã™ã‚‹å°‚é–€å®¶ã§ã™ã€‚"},
                {"role": "user", "content": prompt}
            ],
            temperature=0.3
        )

        elapsed = time.time() - start_time

        # ãƒˆãƒ¼ã‚¯ãƒ³ä½¿ç”¨é‡ã‚’å–å¾—
        usage = response.usage
        result['time'] = elapsed
        result['prompt_tokens'] = usage.prompt_tokens if usage else 0
        result['completion_tokens'] = usage.completion_tokens if usage else 0
        result['total_tokens'] = usage.total_tokens if usage else 0

        # Mermaidã‚³ãƒ¼ãƒ‰ã‚’å–å¾—
        mermaid_code = response.choices[0].message.content.strip()
        mermaid_code = mermaid_code.replace('```mermaid', '').replace('```', '').strip()
        result['mermaid_code'] = mermaid_code

        print(f"âœ… {model}: {elapsed:.2f}ç§’, {result['total_tokens']} tokens")

    except Exception as e:
        result['error'] = str(e)
        print(f"âŒ {model}: ã‚¨ãƒ©ãƒ¼ - {e}")

    return result

# ===============================================
#  ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯å®Ÿè¡Œ
# ===============================================
def run_benchmark():
    """è¤‡æ•°ã®ãƒ¢ãƒ‡ãƒ«ã§ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã‚’å®Ÿè¡Œï¼ˆå„ãƒ¢ãƒ‡ãƒ«5å›ï¼‰"""

    print("=" * 60)
    print("Mermaidå›³ç”Ÿæˆ ãƒ¢ãƒ‡ãƒ«åˆ¥ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ï¼ˆå„ãƒ¢ãƒ‡ãƒ«5å›å®Ÿè¡Œï¼‰")
    print("=" * 60)
    print()

    # ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
    print("ğŸ“– ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿ä¸­...")
    story_text = load_test_data()
    question = "ã‚«ãƒŠãƒ‡ã£ã¦èª°ã§ã™ã‹ï¼Ÿ"
    main_focus = "ã‚«ãƒŠãƒ‡"

    print(f"   - æœ¬æ–‡æ–‡å­—æ•°: {len(story_text):,} æ–‡å­—")
    print(f"   - è³ªå•: {question}")
    print(f"   - ä¸­å¿ƒäººç‰©: {main_focus}")
    print()

    # ãƒ†ã‚¹ãƒˆå¯¾è±¡ã®ãƒ¢ãƒ‡ãƒ«
    models_to_test = [
        "gpt-4o-mini",      # æœ€ã‚‚é«˜é€Ÿãƒ»ä½ã‚³ã‚¹ãƒˆ
        "gpt-4o",           # ãƒãƒ©ãƒ³ã‚¹å‹
        "gpt-4.1",          # ç¾åœ¨ä½¿ç”¨ä¸­ï¼ˆæ¯”è¼ƒç”¨ï¼‰
        "o1-mini",          # æ¨è«–ç‰¹åŒ–å‹ï¼ˆå°ï¼‰
        "o3-mini",          # æ¨è«–ç‰¹åŒ–å‹ï¼ˆæœ€æ–°ï¼‰
    ]

    # å„ãƒ¢ãƒ‡ãƒ«ã‚’5å›å®Ÿè¡Œ
    num_runs = 5
    results = []

    print(f"ğŸ§ª å„ãƒ¢ãƒ‡ãƒ«ã§{num_runs}å›ãšã¤Mermaidå›³ã‚’ç”Ÿæˆä¸­...\n")

    total_tests = len(models_to_test) * num_runs
    current_test = 0

    for model in models_to_test:
        print(f"\n{'=' * 60}")
        print(f"ãƒ¢ãƒ‡ãƒ«: {model}")
        print(f"{'=' * 60}")

        for run in range(1, num_runs + 1):
            current_test += 1
            print(f"  [{current_test}/{total_tests}] {model} - å®Ÿè¡Œ {run}/{num_runs}...")

            result = generate_mermaid_rough(
                model=model,
                question=question,
                story_text=story_text,
                main_focus=main_focus
            )

            # å®Ÿè¡Œå›æ•°ã‚’è¨˜éŒ²
            result['run'] = run
            results.append(result)

            # APIåˆ¶é™ã‚’è€ƒæ…®ã—ã¦å°‘ã—å¾…æ©Ÿ
            if current_test < total_tests:
                time.sleep(1)

    # çµæœã‚’CSVã«ä¿å­˜
    save_results_to_csv(results)

    # è©³ç´°ã‚’ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
    save_results_to_text(results, story_text, question)

    # ã‚µãƒãƒªãƒ¼è¡¨ç¤º
    print_summary(results)

# ===============================================
#  çµæœã®ä¿å­˜
# ===============================================
def save_results_to_csv(results):
    """çµæœã‚’CSVãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜"""
    output_file = "benchmark_results.csv"

    with open(output_file, 'w', newline='', encoding='utf-8') as f:
        writer = csv.writer(f)

        # ãƒ˜ãƒƒãƒ€ãƒ¼
        writer.writerow([
            "Model",
            "Run",
            "Time (sec)",
            "Prompt Tokens",
            "Completion Tokens",
            "Total Tokens",
            "Success",
            "Error"
        ])

        # ãƒ‡ãƒ¼ã‚¿
        for r in results:
            writer.writerow([
                r['model'],
                r.get('run', 1),
                f"{r['time']:.2f}",
                r['prompt_tokens'],
                r['completion_tokens'],
                r['total_tokens'],
                "OK" if r['error'] is None else "FAILED",
                r['error'] if r['error'] else ""
            ])

    print(f"ğŸ’¾ çµæœã‚’ {output_file} ã«ä¿å­˜ã—ã¾ã—ãŸ")

def save_results_to_text(results, story_text, question):
    """è©³ç´°çµæœã‚’ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜"""
    output_file = "benchmark_details.txt"

    with open(output_file, 'w', encoding='utf-8') as f:
        f.write("=" * 80 + "\n")
        f.write("Mermaidå›³ç”Ÿæˆ ãƒ¢ãƒ‡ãƒ«åˆ¥ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ è©³ç´°çµæœ\n")
        f.write("=" * 80 + "\n\n")

        f.write(f"å®Ÿè¡Œæ—¥æ™‚: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
        f.write(f"è³ªå•: {question}\n")
        f.write(f"æœ¬æ–‡æ–‡å­—æ•°: {len(story_text):,} æ–‡å­—\n\n")

        for i, r in enumerate(results, 1):
            f.write(f"\n{'=' * 80}\n")
            f.write(f"[{i}] {r['model']}\n")
            f.write(f"{'=' * 80}\n\n")

            if r['error']:
                f.write(f"âŒ ã‚¨ãƒ©ãƒ¼: {r['error']}\n")
            else:
                f.write(f"å‡¦ç†æ™‚é–“: {r['time']:.2f} ç§’\n")
                f.write(f"ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒˆãƒ¼ã‚¯ãƒ³: {r['prompt_tokens']:,}\n")
                f.write(f"å®Œäº†ãƒˆãƒ¼ã‚¯ãƒ³: {r['completion_tokens']:,}\n")
                f.write(f"åˆè¨ˆãƒˆãƒ¼ã‚¯ãƒ³: {r['total_tokens']:,}\n\n")

                f.write("ç”Ÿæˆã•ã‚ŒãŸMermaidã‚³ãƒ¼ãƒ‰:\n")
                f.write("-" * 80 + "\n")
                f.write(r['mermaid_code'] + "\n")
                f.write("-" * 80 + "\n")

    print(f"ğŸ“„ è©³ç´°ã‚’ {output_file} ã«ä¿å­˜ã—ã¾ã—ãŸ")

# ===============================================
#  ã‚µãƒãƒªãƒ¼è¡¨ç¤º
# ===============================================
def print_summary(results):
    """çµæœã®ã‚µãƒãƒªãƒ¼ã‚’è¡¨ç¤ºï¼ˆ5å›å®Ÿè¡Œã®å¹³å‡å€¤ã§æ¯”è¼ƒï¼‰"""
    import statistics

    print()
    print("=" * 90)
    print("ğŸ“Š ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯çµæœã‚µãƒãƒªãƒ¼ï¼ˆå„ãƒ¢ãƒ‡ãƒ«5å›å®Ÿè¡Œã®çµ±è¨ˆï¼‰")
    print("=" * 90)
    print()

    # ãƒ¢ãƒ‡ãƒ«ã”ã¨ã«çµæœã‚’é›†è¨ˆ
    model_stats = {}
    for r in results:
        if r['error'] is not None:
            continue

        model = r['model']
        if model not in model_stats:
            model_stats[model] = {
                'times': [],
                'tokens': []
            }

        model_stats[model]['times'].append(r['time'])
        model_stats[model]['tokens'].append(r['total_tokens'])

    if not model_stats:
        print("âŒ ã™ã¹ã¦ã®ãƒ¢ãƒ‡ãƒ«ã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ")
        return

    # å„ãƒ¢ãƒ‡ãƒ«ã®çµ±è¨ˆã‚’è¨ˆç®—
    summary = []
    for model, stats in model_stats.items():
        if len(stats['times']) > 0:
            summary.append({
                'model': model,
                'avg_time': statistics.mean(stats['times']),
                'min_time': min(stats['times']),
                'max_time': max(stats['times']),
                'std_time': statistics.stdev(stats['times']) if len(stats['times']) > 1 else 0,
                'avg_tokens': statistics.mean(stats['tokens']),
                'num_runs': len(stats['times'])
            })

    # å¹³å‡æ™‚é–“ã§ã‚½ãƒ¼ãƒˆ
    summary.sort(key=lambda x: x['avg_time'])

    # æœ€é€Ÿã®ãƒ¢ãƒ‡ãƒ«ã‚’åŸºæº–ã«ç›¸å¯¾é€Ÿåº¦ã‚’è¨ˆç®—
    fastest_avg = summary[0]['avg_time']

    print(f"{'é †ä½':<4} {'ãƒ¢ãƒ‡ãƒ«':<15} {'å¹³å‡æ™‚é–“':<12} {'æœ€å°-æœ€å¤§':<20} {'æ¨™æº–åå·®':<10} {'ç›¸å¯¾é€Ÿåº¦':<10}")
    print("-" * 90)

    for i, s in enumerate(summary, 1):
        relative_speed = s['avg_time'] / fastest_avg
        print(f"{i:<4} {s['model']:<15} {s['avg_time']:>10.2f}s  "
              f"{s['min_time']:>6.2f}s - {s['max_time']:>6.2f}s  "
              f"Â±{s['std_time']:>6.2f}s  {relative_speed:>8.2f}x")

    print()

    # å¤±æ•—ã—ãŸãƒ¢ãƒ‡ãƒ«
    failed_models = set()
    for r in results:
        if r['error'] is not None:
            failed_models.add((r['model'], r['error']))

    if failed_models:
        print("âš ï¸  ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ãŸãƒ¢ãƒ‡ãƒ«:")
        for model, error in failed_models:
            print(f"   - {model}: {error}")
        print()

    # æ¨å¥¨äº‹é …
    print("ğŸ’¡ æ¨å¥¨äº‹é …:")
    if summary:
        fastest = summary[0]
        print(f"   - æœ€é€Ÿï¼ˆå¹³å‡ï¼‰: {fastest['model']} ({fastest['avg_time']:.2f}ç§’)")

        # gpt-4.1ã¨ã®æ¯”è¼ƒ
        gpt41_stats = next((s for s in summary if s['model'] == 'gpt-4.1'), None)
        if gpt41_stats:
            speedup = gpt41_stats['avg_time'] / fastest['avg_time']
            time_saved = gpt41_stats['avg_time'] - fastest['avg_time']
            print(f"   - gpt-4.1ã¨æ¯”è¼ƒã—ã¦ {speedup:.2f}x é«˜é€ŸåŒ–")
            print(f"   - 1å›ã‚ãŸã‚Šã®æ™‚é–“çŸ­ç¸®: {time_saved:.2f}ç§’")
            print(f"   - 100å›å®Ÿè¡Œã§ç´„ {time_saved * 100 / 60:.1f}åˆ† ã®çŸ­ç¸®")

    print()

# ===============================================
#  ãƒ¡ã‚¤ãƒ³å‡¦ç†
# ===============================================
if __name__ == "__main__":
    try:
        run_benchmark()
        print("âœ… ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯å®Œäº†!")
        print()
        print("æ¬¡ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç¢ºèªã—ã¦ãã ã•ã„:")
        print("  - benchmark_results.csv (CSVå½¢å¼ã®çµæœ)")
        print("  - benchmark_details.txt (è©³ç´°ãªãƒ­ã‚°)")

    except KeyboardInterrupt:
        print("\n\nâš ï¸  ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«ã‚ˆã£ã¦ä¸­æ–­ã•ã‚Œã¾ã—ãŸ")
    except Exception as e:
        print(f"\n\nâŒ ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        import traceback
        traceback.print_exc()
